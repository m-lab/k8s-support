#cloud-config

write_files:

- path: /etc/systemd/system/token-server.service
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=token-server
    After=docker.service
    Requires=docker.service

    # Run the k8s-token-server (supporting the ePoxy Extension API), such that:
    #
    #   1) the host root (/) is mounted read-only in the container as /ro
    #   2) the host etc (/etc) is mounted read-only as the container's /etc
    #
    # The first gives access the kubeadm command.
    # The second gives kubeadm read access to /etc/kubernetes/admin.conf.
    [Service]
    TimeoutStartSec=120
    Restart=always
    ExecStartPre=-/usr/bin/docker stop %N
    ExecStartPre=-/usr/bin/docker rm %N
    ExecStart=/usr/bin/docker run --publish 8800:8800 \
                                  --volume /etc:/etc:ro \
                                  --volume /:/ro:ro \
                                  --name %N -- \
                                  measurementlab/epoxy-extensions:token_server-v0.2.0 \
                                  -command /ro/opt/bin/kubeadm
    ExecStop=/usr/bin/docker stop %N

    [Install]
    WantedBy=multi-user.target

- path: /etc/systemd/system/bmc-store-password.service
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=bmc-store-password
    After=docker.service
    Requires=docker.service

    [Service]
    TimeoutStartSec=120
    Restart=always
    ExecStartPre=-/usr/bin/docker stop %N
    ExecStartPre=-/usr/bin/docker rm %N
    ExecStart=/usr/bin/docker run --publish 8801:8801 \
                                  --name %N -- \
                                  measurementlab/epoxy-extensions:bmc_store_password-v0.2.0
    ExecStop=/usr/bin/docker stop %N

    [Install]
    WantedBy=multi-user.target

- path: /etc/systemd/system/gcp-loadbalancer-proxy.service
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=gcp-loadbalancer-proxy
    After=docker.service
    Requires=docker.service

    [Service]
    TimeoutStartSec=120
    Restart=always
    ExecStartPre=-/usr/bin/docker stop %N
    ExecStartPre=-/usr/bin/docker rm %N
    ExecStart=/usr/bin/docker run --publish 8080:8080 \
                                  --network host \
                                  --name %N -- \
                                  measurementlab/gcp-loadbalancer-proxy:v1.0 \
                                  -url https://localhost:6443
    ExecStop=/usr/bin/docker stop %N

    [Install]
    WantedBy=multi-user.target

- path: /etc/systemd/system/reboot-node.service
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=reboot-node.service

    [Service]
    Type=oneshot
    ExecStart=/opt/bin/reboot-node

- path: /etc/systemd/system/reboot-node.timer
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=Run reboot-node.service daily

    [Timer]
    OnCalendar=Mon..Fri 15:00:00

    [Install]
    WantedBy=multi-user.target

- path: /etc/ssh/sshd_config
  permissions: 0600
  owner: root:root
  content: |
    UsePrivilegeSeparation sandbox
    Subsystem sftp internal-sftp
    ClientAliveInterval 180
    UseDNS no
    UsePAM yes
    PrintLastLog no # handled by PAM
    PrintMotd no # handled by PAM
    PasswordAuthentication no
    ChallengeResponseAuthentication no
    PermitRootLogin no

# We have run up against "no space left on device" errors, when clearly
# there is plenty of free disk space. It seems this could likely be related
# to this:
# https://github.com/kubernetes/kubernetes/issues/7815#issuecomment-124566117
# To be sure we don't hit the limit of fs.inotify.max_user_watches, increase
# it from the default of 8192.
- path: /etc/sysctl.d/fs_inotify.conf
  permissions: 0644
  owner: root:root
  content: |
    fs.inotify.max_user_watches=131072

# The smallest of scripts to reboot the machine.
- path: /opt/bin/reboot-node
  permissions: 0744
  owner: root:root
  content: |
    #!/bin/bash
    REBOOT_DAY=$(cat /etc/reboot-node-day)
    TODAY=$(date +%a)
    source /root/.profile
    # Members are listed whether they are healthy or not.
    ETCD_ENDPOINTS=$(/opt/bin/etcdctl member list | egrep -o 'https://[0-9.]+:2379' | paste -s -d, -)
    export ETCDCTL_ENDPOINTS="${ETCD_ENDPOINTS}"
    # Currently healthy endpoints are reported on stderr, along with actual
    # errors: https://github.com/etcd-io/etcd/pull/11322. That issue is closed
    # and a related PR merged, but the fix is not yet part of the current
    # Ubuntu version 3.4.7 (2020-07-16). When it is in the curernt Ubuntu
    # release then this code can be refactored.
    ETCD_HEALTHY_COUNT=$(/opt/bin/etcdctl endpoint health 2>&1 \
        | grep -P '(?<!un)healthy' | wc -l)
    if [[ "${REBOOT_DAY}" != "${TODAY}" ]]; then
      echo "Reboot day ${REBOOT_DAY} doesn't equal today: ${TODAY}. Not rebooting."
      exit 0
    fi
    if [[ "${ETCD_HEALTHY_COUNT}" -lt "3" ]]; then
      echo "There are less than 3 healthy etcd cluster members. Not rebooting."
      exit 1
    fi
    echo "Reboot day ${REBOOT_DAY} equals today: ${TODAY}. Rebooting node."
    /sbin/reboot

- path: /etc/docker/daemon.json
  permissions: 0644
  owner: root:root
  content: |
    {
      "exec-opts": [
        "native.cgroupdriver=systemd"
      ],
      "log-driver": "json-file",
      "log-opts": {
        "max-size": "100m"
      },
      "storage-driver": "overlay2"
    }

packages:
- docker.io
- socat
- vim
package_update: true
package_upgrade: true

runcmd:
- systemctl daemon-reload
- systemctl enable docker
- systemctl start docker
- systemctl enable gcp-loadbalancer-proxy.service
- systemctl start gcp-loadbalancer-proxy.service
- systemctl enable reboot-node.timer
- systemctl start reboot-node.timer
- systemctl enable token-server.service
- systemctl start token-server.service
- systemctl enable bmc-store-password.service
- systemctl start bmc-store-password.service
