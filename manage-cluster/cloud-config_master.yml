#cloud-config

write_files:

- path: /etc/systemd/system/token-server.service
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=token-server
    After=docker.service
    Requires=docker.service

    # Run the k8s-token-server (supporting the ePoxy Extension API), such that:
    #
    #   1) the host root (/) is mounted read-only in the container as /ro
    #   2) the host etc (/etc) is mounted read-only as the container's /etc
    #
    # The first gives access the kubeadm command.
    # The second gives kubeadm read access to /etc/kubernetes/admin.conf.
    [Service]
    TimeoutStartSec=120
    Restart=always
    ExecStartPre=-/usr/bin/docker stop %N
    ExecStartPre=-/usr/bin/docker rm %N
    ExecStart=/usr/bin/docker run --publish 8800:8800 \
                                  --volume /etc:/etc:ro \
                                  --volume /:/ro:ro \
                                  --name %N -- \
                                  measurementlab/epoxy-extensions:token_server-v0.2.1 \
                                  -command /ro/opt/bin/kubeadm
    ExecStop=/usr/bin/docker stop %N

    [Install]
    WantedBy=multi-user.target

- path: /etc/systemd/system/bmc-store-password.service
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=bmc-store-password
    After=docker.service
    Requires=docker.service

    [Service]
    TimeoutStartSec=120
    Restart=always
    ExecStartPre=-/usr/bin/docker stop %N
    ExecStartPre=-/usr/bin/docker rm %N
    ExecStart=/usr/bin/docker run --publish 8801:8801 \
                                  --name %N -- \
                                  measurementlab/epoxy-extensions:bmc_store_password-v0.2.1
    ExecStop=/usr/bin/docker stop %N

    [Install]
    WantedBy=multi-user.target

- path: /etc/systemd/system/reboot-node.service
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=reboot-node.service

    [Service]
    Type=oneshot
    ExecStart=/opt/bin/reboot-node

- path: /etc/systemd/system/reboot-node.timer
  permissions: 0644
  owner: root
  content: |
    [Unit]
    Description=Run reboot-node.service daily

    [Timer]
    OnCalendar=Mon..Fri 15:00:00

    [Install]
    WantedBy=multi-user.target

- path: /etc/ssh/sshd_config
  permissions: 0600
  owner: root:root
  content: |
    Subsystem sftp internal-sftp
    ClientAliveInterval 180
    UseDNS no
    UsePAM yes
    PrintLastLog no # handled by PAM
    PrintMotd no # handled by PAM
    PasswordAuthentication no
    ChallengeResponseAuthentication no
    PermitRootLogin no

# This is the default containerd config, as produced by `container config
# default` with two small changes. It changes the runc "runtime_type" to
# "io.containerd.runc.v2" and adds:
# [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
#    SystemdCgroup = true
- path: /etc/containerd/config.toml
  permissions: 0644
  owner: root:root
  content: |
    version = 2
    root = "/var/lib/containerd"
    state = "/run/containerd"
    plugin_dir = ""
    disabled_plugins = []
    required_plugins = []
    oom_score = 0

    [grpc]
      address = "/run/containerd/containerd.sock"
      tcp_address = ""
      tcp_tls_cert = ""
      tcp_tls_key = ""
      uid = 0
      gid = 0
      max_recv_message_size = 16777216
      max_send_message_size = 16777216

    [ttrpc]
      address = ""
      uid = 0
      gid = 0

    [debug]
      address = ""
      uid = 0
      gid = 0
      level = ""

    [metrics]
      address = ""
      grpc_histogram = false

    [cgroup]
      path = ""

    [timeouts]
      "io.containerd.timeout.shim.cleanup" = "5s"
      "io.containerd.timeout.shim.load" = "5s"
      "io.containerd.timeout.shim.shutdown" = "3s"
      "io.containerd.timeout.task.state" = "2s"

    [plugins]
      [plugins."io.containerd.gc.v1.scheduler"]
        pause_threshold = 0.02
        deletion_threshold = 0
        mutation_threshold = 100
        schedule_delay = "0s"
        startup_delay = "100ms"
      [plugins."io.containerd.grpc.v1.cri"]
        disable_tcp_service = true
        stream_server_address = "127.0.0.1"
        stream_server_port = "0"
        stream_idle_timeout = "4h0m0s"
        enable_selinux = false
        sandbox_image = "k8s.gcr.io/pause:3.1"
        stats_collect_period = 10
        systemd_cgroup = false
        enable_tls_streaming = false
        max_container_log_line_size = 16384
        disable_cgroup = false
        disable_apparmor = false
        restrict_oom_score_adj = false
        max_concurrent_downloads = 3
        disable_proc_mount = false
        [plugins."io.containerd.grpc.v1.cri".containerd]
          snapshotter = "overlayfs"
          default_runtime_name = "runc"
          no_pivot = false
          [plugins."io.containerd.grpc.v1.cri".containerd.default_runtime]
            runtime_type = ""
            runtime_engine = ""
            runtime_root = ""
            privileged_without_host_devices = false
          [plugins."io.containerd.grpc.v1.cri".containerd.untrusted_workload_runtime]
            runtime_type = ""
            runtime_engine = ""
            runtime_root = ""
            privileged_without_host_devices = false
          [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
              runtime_type = "io.containerd.runc.v2"
              runtime_engine = ""
              runtime_root = ""
              privileged_without_host_devices = false
              [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
                SystemdCgroup = true
        [plugins."io.containerd.grpc.v1.cri".cni]
          bin_dir = "/opt/cni/bin"
          conf_dir = "/etc/cni/net.d"
          max_conf_num = 1
          conf_template = ""
        [plugins."io.containerd.grpc.v1.cri".registry]
          [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
            [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
              endpoint = ["https://registry-1.docker.io"]
        [plugins."io.containerd.grpc.v1.cri".x509_key_pair_streaming]
          tls_cert_file = ""
          tls_key_file = ""
      [plugins."io.containerd.internal.v1.opt"]
        path = "/opt/containerd"
      [plugins."io.containerd.internal.v1.restart"]
        interval = "10s"
      [plugins."io.containerd.metadata.v1.bolt"]
        content_sharing_policy = "shared"
      [plugins."io.containerd.monitor.v1.cgroups"]
        no_prometheus = false
      [plugins."io.containerd.runtime.v1.linux"]
        shim = "containerd-shim"
        runtime = "runc"
        runtime_root = ""
        no_shim = false
        shim_debug = false
      [plugins."io.containerd.runtime.v2.task"]
        platforms = ["linux/amd64"]
      [plugins."io.containerd.service.v1.diff-service"]
        default = ["walking"]
      [plugins."io.containerd.snapshotter.v1.devmapper"]
        root_path = ""
        pool_name = ""
        base_image_size = ""

# We have run up against "no space left on device" errors, when clearly
# there is plenty of free disk space. It seems this could likely be related
# to this:
# https://github.com/kubernetes/kubernetes/issues/7815#issuecomment-124566117
# To be sure we don't hit the limit of fs.inotify.max_user_watches, increase
# it from the default of 8192.
- path: /etc/sysctl.d/fs_inotify.conf
  permissions: 0644
  owner: root:root
  content: |
    fs.inotify.max_user_watches=131072

# The smallest of scripts to reboot the machine.
- path: /opt/bin/reboot-node
  permissions: 0744
  owner: root:root
  content: |
    #!/bin/bash
    REBOOT_DAY=$(cat /etc/reboot-node-day)
    TODAY=$(date +%a)
    source /root/.profile
    # Members are listed whether they are healthy or not.
    ETCD_ENDPOINTS=$(/opt/bin/etcdctl member list | egrep -o 'https://[0-9.]+:2379' | paste -s -d, -)
    export ETCDCTL_ENDPOINTS="${ETCD_ENDPOINTS}"
    # Currently healthy endpoints are reported on stderr, along with actual
    # errors: https://github.com/etcd-io/etcd/pull/11322. That issue is closed
    # and a related PR merged, but the fix is not yet part of the current
    # Ubuntu version 3.4.7 (2020-07-16). When it is in the curernt Ubuntu
    # release then this code can be refactored.
    ETCD_HEALTHY_COUNT=$(/opt/bin/etcdctl endpoint health 2>&1 \
        | grep -P '(?<!un)healthy' | wc -l)
    if [[ "${REBOOT_DAY}" != "${TODAY}" ]]; then
      echo "Reboot day ${REBOOT_DAY} doesn't equal today: ${TODAY}. Not rebooting."
      exit 0
    fi
    if [[ "${ETCD_HEALTHY_COUNT}" -lt "3" ]]; then
      echo "There are less than 3 healthy etcd cluster members. Not rebooting."
      exit 1
    fi
    echo "Reboot day ${REBOOT_DAY} equals today: ${TODAY}. Rebooting node."
    /sbin/reboot

- path: /etc/docker/daemon.json
  permissions: 0644
  owner: root:root
  content: |
    {
      "exec-opts": [
        "native.cgroupdriver=systemd"
      ],
      "log-driver": "json-file",
      "log-opts": {
        "max-size": "100m"
      },
      "storage-driver": "overlay2"
    }

packages:
- docker.io
- socat
- vim
package_update: true
package_upgrade: true

runcmd:
- systemctl daemon-reload
- systemctl enable docker
- systemctl start docker
- systemctl enable reboot-node.timer
- systemctl start reboot-node.timer
- systemctl enable token-server.service
- systemctl start token-server.service
- systemctl enable bmc-store-password.service
- systemctl start bmc-store-password.service
