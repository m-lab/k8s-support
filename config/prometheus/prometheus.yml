# M-Lab Prometheus configuration.

global:
  scrape_interval:     60s  # Set the scrape interval to every 60 seconds.
  evaluation_interval: 60s  # Evaluate rules every 60 seconds.

rule_files:
  - /etc/prometheus/rules.yml
#  - /etc/prometheus/alerts.yml

# Scrape configurations.
scrape_configs:

  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
      - role: endpoints

    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    relabel_configs:
      - source_labels: [__meta_kubernetes_namespace,
                        __meta_kubernetes_service_name,
                        __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

  - job_name: 'kubernetes-etcd'
    kubernetes_sd_configs:
      - role: node

    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      cert_file: /etc/prometheus/tls/client.crt
      key_file: /etc/prometheus/tls/client.key
      # The CA certificate at
      # /var/run/secrets/kubernetes.io/serviceaccount/ca.crt is for the API
      # server. etcd has its own CA certificate which isn't available to us, so
      # we just skip verifying it. This scraping is happening over the private
      # VPC network, so this is probably okay.
      insecure_skip_verify: true

    relabel_configs:
      - source_labels: [__meta_kubernetes_node_name]
        action: keep
        regex: master-platform-cluster-.*

      - source_labels: [__meta_kubernetes_node_address_InternalIP]
        regex: (.*)
        target_label: __address__
        replacement: ${1}:2379


  # Scrape config for kubernetes nodes.
  - job_name: 'kubernetes-nodes'
    kubernetes_sd_configs:
      - role: node

    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      # Node /metrics in v1.6+ are accessible via a proxy through the
      # kubernetes api server. So, we must update the target and metric path.
      - target_label: __address__
        # TODO: replace with dns name once coredns is working.
        # replacement: kubernetes.default.svc:443
        replacement: 172.25.0.1:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics
      # Add a node label to each target node that is auto-discovered.
      - source_labels: [__meta_kubernetes_node_name]
        action: replace
        target_label: node
      # Add a machine label to each target node that is auto-discovered.
      - source_labels: [__meta_kubernetes_node_name]
        action: replace
        target_label: machine


  # Scrape config for kubernetes pods.
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod

    relabel_configs:
      # node-exporter is scraped in a separate job.
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
        regex: https
        action: drop

      # socat proxy enables easy access to pprof targets but accidentally
      # duplicates metric collection. The annotation mechanism applies at the pod
      # level not at individual containers. So, this rule drops metrics with
      # socat containers.
      - source_labels: [__meta_kubernetes_pod_container_name]
        regex: socat-.*
        action: drop

      # For inventory, record whether a pod is ready. This helps distinguish
      # between: missing from inventory, not ready and failing, ready but
      # failing, ready and working.
      # and working.
      - source_labels: [__meta_kubernetes_pod_ready]
        action: replace
        target_label: ready

      # Check for the prometheus.io/scrape=true annotation.
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true

      # Only keep containers that have a declared container port.
      - source_labels: [__meta_kubernetes_pod_container_port_number]
        action: keep
        regex: (\d+)

      # Copy all pod labels from kubernetes to the Prometheus metrics.
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)

      # Add the kubernetes namespace as a Prometheus label.
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace

      # Add a machine label to make it easier to join these metrics with
      # existing metrics that use machine instead of the node label.
      - source_labels: [__meta_kubernetes_pod_node_name]
        action: replace
        target_label: machine

      # Identify the deployment name for replica set or daemon set.  Pods
      # created by deployments or daemon sets are processed here. The
      # following two rules recognize these two cases.
      #
      # 1: For DaemonSet, remove the last 5-digit pod name hash.
      #   e.g. node-exporter-ltxgz
      - source_labels: [__meta_kubernetes_pod_controller_kind, __meta_kubernetes_pod_name]
        action: replace
        regex: DaemonSet;(.*)(-[^-]{5})
        replacement: $1
        target_label: deployment

      # 2: For ReplicaSet, remove the last 10-digit + 5-digit pod name hash.
      # In the case of a daemon set that does not have the trailing hash, the
      # regex will not match and deployment remains unchanged.
      #   e.g. prometheus-server-3165440997-ppf9w
      - source_labels: [__meta_kubernetes_pod_controller_kind, __meta_kubernetes_pod_name]
        action: replace
        regex: ReplicaSet;(.*)(-[^-]+)(-[^-]{5})
        replacement: $1
        target_label: deployment

      # Add the kubernetes pod name.
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod

      # Add the kubernetes pod container name.
      - source_labels: [__meta_kubernetes_pod_container_name]
        action: replace
        target_label: container


  # Scrape config for kubernetes service endpoints.
  - job_name: 'kubernetes-service-endpoints'
    kubernetes_sd_configs:
      - role: endpoints

    relabel_configs:
      # Check for the prometheus.io/scrape=true annotation.
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      # Check for the prometheus.io/port=<port> annotation.
      - source_labels: [__address__,
                        __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        # A google/re2 regex, matching addresses with or without default ports.
        # NB: this will not work with IPv6 addresses. But, atm, kubernetes uses
        # IPv4 addresses for internal network and GCE doesn not support IPv6.
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      # Copy all service labels from kubernetes to the Prometheus metrics.
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      # Add the kubernetes namespace as a Prometheus label.
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      # Add the kubernetes service name as a Prometheus label.
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name


  # This job will scrape workloads that are being proxies by kube-rbac-proxy.
  # These are workloads that use hostNetwork=True and therefore export metrics on
  # the public interface. For this reason we put them behind kube-rbac-proxy to
  # prevent the general public from scraping or abusing these pods.
  - job_name: 'proxied-workloads'
    kubernetes_sd_configs:
      - role: pod

    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
        regex: https
        action: keep

      # For inventory, record whether a pod is ready. This helps distinguish
      # between: missing from inventory, not ready and failing, ready but
      # failing, ready and working.
      # and working.
      - source_labels: [__meta_kubernetes_pod_ready]
        action: replace
        target_label: ready

      # Check for the prometheus.io/scrape=true annotation.
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true

      # Only keep containers that have a declared container port.
      - source_labels: [__meta_kubernetes_pod_container_port_number]
        action: keep
        regex: (\d+)

      # Copy all pod labels from kubernetes to the Prometheus metrics.
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)

      # Add the kubernetes namespace as a Prometheus label.
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace

      # Add the node name to a label named node.
      - source_labels: [__meta_kubernetes_pod_node_name]
        action: replace
        target_label: node

      # Add a machine label to each target node that is auto-discovered.
      - source_labels: [__meta_kubernetes_pod_node_name]
        action: replace
        target_label: machine

      # Identify the deployment name for replica set or daemon set.  Pods
      # created by deployments or daemon sets are processed here. The
      # following two rules recognize these two cases.
      #
      # 1: For DaemonSet, remove the last 5-digit pod name hash.
      #   e.g. node-exporter-ltxgz
      - source_labels: [__meta_kubernetes_pod_controller_kind, __meta_kubernetes_pod_name]
        action: replace
        regex: DaemonSet;(.*)(-[^-]{5})
        replacement: $1
        target_label: deployment

      # 2: For ReplicaSet, remove the last 10-digit + 5-digit pod name hash.
      # In the case of a daemon set that does not have the trailing hash, the
      # regex will not match and deployment remains unchanged.
      #   e.g. prometheus-server-3165440997-ppf9w
      - source_labels: [__meta_kubernetes_pod_controller_kind, __meta_kubernetes_pod_name]
        action: replace
        regex: ReplicaSet;(.*)(-[^-]+)(-[^-]{5})
        replacement: $1
        target_label: deployment

      # Add the kubernetes pod name.
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod

      # Add the kubernetes pod container name.
      - source_labels: [__meta_kubernetes_pod_container_name]
        action: replace
        target_label: container
