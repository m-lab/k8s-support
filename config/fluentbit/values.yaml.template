config:
  customParsers: |
    [PARSER]
        # http://rubular.com/r/tjUt3Awgg4
        Name cri
        Format regex
        Regex ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
  filters: |
    @INCLUDE filter.conf
  inputs: |
    [INPUT]
        Name tail
        Path /var/log/containers/*.log
        Parser cri
        Tag kube.*
        Mem_Buf_Limit 32MB
        Buffer_Chunk_Size 64KB
        Buffer_Max_Size 1MB
        Skip_Long_Lines On
        storage.type filesystem
    # The systemd input plugin has fairly rudimentary ability to filter
    # messages. It only has the ability to join filters on AND or OR, and you
    # cannot use globbing or regexs. The following systemd inputs just break
    # out each particular PRIORITY level we want from the kernel.
    [INPUT]
        Name systemd
        Tag host.*
        Read_From_Tail On
        Systemd_Filter SYSLOG_IDENTIFIER=kernel
        Systemd_Filter PRIORITY=0
        Systemd_Filter_Type And
    [INPUT]
        Name systemd
        Tag host.*
        Read_From_Tail On
        Systemd_Filter SYSLOG_IDENTIFIER=kernel
        Systemd_Filter PRIORITY=1
        Systemd_Filter_Type And
    [INPUT]
        Name systemd
        Tag host.*
        Read_From_Tail On
        Systemd_Filter SYSLOG_IDENTIFIER=kernel
        Systemd_Filter PRIORITY=2
        Systemd_Filter_Type And
    [INPUT]
        Name systemd
        Tag host.*
        Read_From_Tail On
        Systemd_Filter SYSLOG_IDENTIFIER=kernel
        Systemd_Filter PRIORITY=3
        Systemd_Filter_Type And
    [INPUT]
        Name systemd
        Tag host.*
        Read_From_Tail On
        Systemd_Filter SYSLOG_IDENTIFIER=kernel
        Systemd_Filter PRIORITY=4
        Systemd_Filter_Type And
  outputs: |
    @INCLUDE output.conf
  service: |
    [SERVICE]
        Daemon Off
        Flush {{ .Values.flush }}
        Log_Level {{ .Values.logLevel }}
        Parsers_File custom_parsers.conf
        HTTP_Server  On
        HTTP_Listen  0.0.0.0
        HTTP_PORT    2020
        storage.path /var/lib/fluent-bit
dnsConfig:
  options:
  - name: ndots
    value: "2"
env:
- name: GOOGLE_APPLICATION_CREDENTIALS
  value: /etc/fluentbit/keys/fluentbit.json
extraVolumes:
- name: credentials
  secret:
    defaultMode: 420
    secretName: fluentbit-credentials
- name: fluent-bit-etc
  emptyDir: {}
extraVolumeMounts:
- name: credentials
  mountPath: /etc/fluentbit/keys
  readOnly: true
- name: fluent-bit-etc
  mountPath: /fluent-bit/etc
flush: 15
image:
  repository: fluent/fluent-bit
  tag: {{K8S_FLUENTBIT_VERSION}}
  pullPolicy: Always
# The fluent-bit Helm chart does not allow the possibility to specify
# environment variables using the k8s downward API. We need the node name when
# pushing to Stackdriver, so this initContainer creates the [OUTPUT]
# configuration, instead of specifying it above in config.outputs. We also use
# the "Use_Kubelet" configuration of the kubernetes filter, which needs to know
# the address on which to contact the kubelet for pod metadata.
initContainers:
- name: create-output-config
  image: busybox
  command:
  - sh
  - -c
  - |
    cat << EOF >> /fluent-bit/etc/output.conf
    [OUTPUT]
        # write the log records that still have the 'kube.*' tags to Cloud Logging
        Name stackdriver
        Match *
        Resource generic_node
        location {{PROJECT}}
        namespace ${NODE_NAME}
        node_id ${NODE_NAME}
        export_to_project_id {{PROJECT}}
        # Don't try to push a chunk forever.
        Retry_Limit 10
        # Default timeout is 10s. Increase this a bit to workaround a slow or
        # flaky network connection.
        net.connect_timeout 60
        # We have been seeing a lot of "Timeout while contacting DNS servers"
        # errors in fluent-bit logs and fluent bit not being able to upload
        # logs. Several Github issues reporting this had users saying that this
        # was at least partially mitigated by this setting (using TCP instead
        # of UDP).
        net.dns.mode TCP
        # Don't continue to fill up the filesystem with buffered chunks when
        # pushing logs to Stackdriver isn't working for some reason.
        storage.total_limit_size 1G
    EOF
    cat << EOF >> /fluent-bit/etc/filter.conf
    [FILTER]
        Name kubernetes
        Match kube.*
        Buffer_Size 0
        Use_Kubelet true
        Kubelet_Host ${KUBELET_HOST}
        tls.verify Off
    EOF
  env:
  - name: NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: KUBELET_HOST
    valueFrom:
      fieldRef:
        fieldPath: status.hostIP
  volumeMounts:
  - name: fluent-bit-etc
    mountPath: /fluent-bit/etc
fullnameOverride: fluentbit
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/scheme: http
  prometheus.io/metrics_path: /api/v1/metrics/prometheus
podLabels:
  workload: fluentbit
rbac:
  create: true
  nodeAccess: true
tolerations:
- effect: NoSchedule
  key: lame-duck
  operator: Exists

