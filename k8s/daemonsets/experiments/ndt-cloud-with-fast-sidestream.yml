apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: ndt-cloud
  namespace: default
spec:
  selector:
    matchLabels:
      run: ndt-cloud
  template:
    metadata:
      labels:
        run: ndt-cloud
      annotations:
        prometheus.io/scrape: 'true'
        k8s.v1.cni.cncf.io/networks: '[
          { "name": "flannel-conf" },
          { "name": "index2ip-index-2-conf" } ]'
    spec:

      # The default grace period after k8s sends SIGTERM is 30s. We extend the
      # grace period to give time for the following shutdown sequence. After the
      # grace period, kubernetes sends SIGKILL.
      #
      # NDT pod shutdown sequence:
      #
      #  * k8s sends SIGTERM to NDT server
      #  * NDT server enables lame duck status
      #  * monitoring reads lame duck status (60s max)
      #  * mlab-ns updates server status (60s max)
      #  * all currently running tests complete. (30s max)
      #
      # TODO: enable before receiving production traffic.
      # terminationGracePeriodSeconds: 150
      #

      # TODO (kinkade): Remove this toleration once we have discovered why
      # the route_controller on platform nodes logs "FailedToCreateRoute [...]
      # Could not create route [...]: instance not found". When this happens the
      # route_controller set the NetworkUnavailable node condition to True,
      # which adds this taint, which, without this toleration, causes the nodes
      # to be unschedulable for the ndt-cloud pods.
      tolerations:
      - key: "node.kubernetes.io/network-unavailable"
        operator: "Exists"
        effect: "NoSchedule"

      nodeSelector:
        mlab/type: 'platform'
      containers:
      - name: ndt-cloud
        image: measurementlab/ndt-cloud:v0.3
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: ndt-tls
          mountPath: /certs
          readOnly: true
      - name: busybox
        image: busybox
        command: ["top"]
        volumeMounts:
        - name: pusher-credentials
          mountPath: /etc/credentials
          readOnly: true
      - name: fast-sidestream
        image: measurementlab/tcp-info:prod-v0.0.1a
        args:
        - -prom=9797
        volumeMounts:
        - name: fast-sidestream-data
          mountPath: /home
      - name: pusher
        image: measurementlab/pusher:v1.1
        env:
        - name: DIRECTORY
          value: /var/spool/fast-sidestream
        - name: GOOGLE_APPLICATION_CREDENTIALS
          value: /etc/credentials/pusher.json
        - name: BUCKET
          valueFrom:
            configMapKeyRef:
              name: pusher-dropbox
              key: bucket
        - name: EXPERIMENT
          value: fast-sidestream
        - name: ARCHIVE_SIZE_THRESHOLD
          value: 1MB
        - name: MLAB_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName

        # TODO: specify the node & site names using kubernetes magic.
        volumeMounts:
        - name: fast-sidestream-data
          mountPath: /var/spool/fast-sidestream
        - name: pusher-credentials
          mountPath: /etc/credentials
          readOnly: true

      initContainers:
      # TODO: this is a hack. Remove the hack by fixing the contents of
      # resolv.conf
      - name: fix-resolv-conf
        image: busybox
        command: ['sh', '-c', 'echo "nameserver 8.8.8.8" > /etc/resolv.conf']

      volumes:
      - name: fast-sidestream-data
        hostPath:
          path: /cache/core/fast-sidestream
          type: DirectoryOrCreate
      - name: pusher-credentials
        secret:
          secretName: pusher-credentials
      - name: ndt-tls
        secret:
          secretName: ndt-tls
